{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 선형회귀모형 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 필요한 패키지 불러오기\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split  \n",
    "from sklearn.linear_model import LinearRegression, Lasso, Ridge\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf # R-style fourmula 사용: 0.5.0 version부터 제공"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>x5</th>\n",
       "      <th>x6</th>\n",
       "      <th>x7</th>\n",
       "      <th>x8</th>\n",
       "      <th>x9</th>\n",
       "      <th>x10</th>\n",
       "      <th>x11</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.0</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.36</td>\n",
       "      <td>20.7</td>\n",
       "      <td>0.045</td>\n",
       "      <td>45.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>1.0010</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.45</td>\n",
       "      <td>8.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.3</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.34</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.049</td>\n",
       "      <td>14.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>0.9940</td>\n",
       "      <td>3.30</td>\n",
       "      <td>0.49</td>\n",
       "      <td>9.5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.1</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.40</td>\n",
       "      <td>6.9</td>\n",
       "      <td>0.050</td>\n",
       "      <td>30.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>0.9951</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.44</td>\n",
       "      <td>10.1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.2</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.32</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.058</td>\n",
       "      <td>47.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>0.9956</td>\n",
       "      <td>3.19</td>\n",
       "      <td>0.40</td>\n",
       "      <td>9.9</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.2</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.32</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.058</td>\n",
       "      <td>47.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>0.9956</td>\n",
       "      <td>3.19</td>\n",
       "      <td>0.40</td>\n",
       "      <td>9.9</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    x1    x2    x3    x4     x5    x6     x7      x8    x9   x10   x11  y\n",
       "0  7.0  0.27  0.36  20.7  0.045  45.0  170.0  1.0010  3.00  0.45   8.8  6\n",
       "1  6.3  0.30  0.34   1.6  0.049  14.0  132.0  0.9940  3.30  0.49   9.5  6\n",
       "2  8.1  0.28  0.40   6.9  0.050  30.0   97.0  0.9951  3.26  0.44  10.1  6\n",
       "3  7.2  0.23  0.32   8.5  0.058  47.0  186.0  0.9956  3.19  0.40   9.9  6\n",
       "4  7.2  0.23  0.32   8.5  0.058  47.0  186.0  0.9956  3.19  0.40   9.9  6"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CSV 파일 자료 읽기\n",
    "white = pd.read_csv(\"white.csv\")   # dataframe\n",
    "white.head()    # white.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    6\n",
       "1    6\n",
       "2    6\n",
       "3    6\n",
       "4    6\n",
       "5    6\n",
       "6    6\n",
       "7    6\n",
       "8    6\n",
       "9    6\n",
       "Name: y, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "white.y[0:10]         # white[\"y\"][0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 7.    0.27  0.36 20.7 ]\n",
      " [ 6.3   0.3   0.34  1.6 ]\n",
      " [ 8.1   0.28  0.4   6.9 ]\n",
      " [ 7.2   0.23  0.32  8.5 ]\n",
      " [ 7.2   0.23  0.32  8.5 ]]\n"
     ]
    }
   ],
   "source": [
    "# numpy를 이용한 자료 읽기\n",
    "white_np = np.loadtxt('white.csv', skiprows=1, delimiter=',', dtype=np.float32) # array 형태\n",
    "print(white_np[0:5,0:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.87790935075541 3 9 0.7843556854710759\n",
      "5.87790935075541 3 9 0.7841955475197752\n"
     ]
    }
   ],
   "source": [
    "# 주요 기술통계\n",
    "print(white.y.mean(axis=0,skipna = True),white.y.min(axis=0), white.y.max(axis=0),white.y.var(axis=0))\n",
    "print(np.mean(white.y,0),np.min(white.y,0),np.max(white.y,0),np.var(white.y,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "# y의 값이 숫자가 아닌 것을 제거\n",
    "print(sum(np.isnan(white[\"y\"])))\n",
    "white = white[-np.isnan(white[\"y\"])]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 7.  ,  0.27,  0.36, ...,  3.  ,  0.45,  8.8 ],\n",
       "       [ 6.3 ,  0.3 ,  0.34, ...,  3.3 ,  0.49,  9.5 ],\n",
       "       [ 8.1 ,  0.28,  0.4 , ...,  3.26,  0.44, 10.1 ],\n",
       "       ...,\n",
       "       [ 6.5 ,  0.24,  0.19, ...,  2.99,  0.46,  9.4 ],\n",
       "       [ 5.5 ,  0.29,  0.3 , ...,  3.34,  0.38, 12.8 ],\n",
       "       [ 6.  ,  0.21,  0.38, ...,  3.26,  0.32, 11.8 ]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 설명변수, 반응변수 분리\n",
    "X = np.array(white.drop([\"y\"],1));  y = np.array(white[\"y\"])\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[7.2000e+00 2.1000e-01 3.7000e-01 1.6000e+00 4.9000e-02 2.3000e+01\n",
      "  9.4000e+01 9.9240e-01 3.1600e+00 4.8000e-01 1.0900e+01]\n",
      " [5.7000e+00 1.5000e-01 2.8000e-01 3.7000e+00 4.5000e-02 5.7000e+01\n",
      "  1.5100e+02 9.9130e-01 3.2200e+00 2.7000e-01 1.1200e+01]\n",
      " [7.0000e+00 2.7000e-01 4.8000e-01 6.1000e+00 4.2000e-02 6.0000e+01\n",
      "  1.8400e+02 9.9566e-01 3.2000e+00 5.0000e-01 9.4000e+00]]\n"
     ]
    }
   ],
   "source": [
    "# train data & test data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=100)  # array 형태\n",
    "print(X_train[0:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.294\n",
      "Model:                            OLS   Adj. R-squared:                  0.291\n",
      "Method:                 Least Squares   F-statistic:                     129.1\n",
      "Date:                Tue, 27 Aug 2019   Prob (F-statistic):          3.70e-248\n",
      "Time:                        08:09:06   Log-Likelihood:                -3878.0\n",
      "No. Observations:                3428   AIC:                             7780.\n",
      "Df Residuals:                    3416   BIC:                             7854.\n",
      "Df Model:                          11                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const        147.5394     21.311      6.923      0.000     105.755     189.324\n",
      "x1             0.0801      0.025      3.246      0.001       0.032       0.128\n",
      "x2            -1.7037      0.136    -12.503      0.000      -1.971      -1.437\n",
      "x3             0.0570      0.117      0.489      0.625      -0.172       0.286\n",
      "x4             0.0817      0.009      9.368      0.000       0.065       0.099\n",
      "x5            -0.0164      0.687     -0.024      0.981      -1.363       1.330\n",
      "x6             0.0050      0.001      4.790      0.000       0.003       0.007\n",
      "x7            -0.0005      0.000     -1.061      0.289      -0.001       0.000\n",
      "x8          -148.2232     21.632     -6.852      0.000    -190.635    -105.811\n",
      "x9             0.7498      0.124      6.048      0.000       0.507       0.993\n",
      "x10            0.7339      0.121      6.082      0.000       0.497       0.971\n",
      "x11            0.2088      0.028      7.557      0.000       0.155       0.263\n",
      "==============================================================================\n",
      "Omnibus:                       65.953   Durbin-Watson:                   1.982\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              123.067\n",
      "Skew:                           0.114   Prob(JB):                     1.89e-27\n",
      "Kurtosis:                       3.900   Cond. No.                     3.54e+05\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 3.54e+05. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "model = sm.OLS(y_train, sm.add_constant(X_train)) # sm.OLS(y,x)와 비교\n",
    "results = model.fit()   # sm.OLS(y_train, sm.add_constant(X_train)).fit() \n",
    "print(results.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.217</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.216</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   339.1</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Tue, 27 Aug 2019</td> <th>  Prob (F-statistic):</th> <td>5.31e-258</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>08:09:07</td>     <th>  Log-Likelihood:    </th> <td> -5755.3</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  4898</td>      <th>  AIC:               </th> <td>1.152e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  4893</td>      <th>  BIC:               </th> <td>1.155e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     4</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th> <td>    2.1214</td> <td>    0.138</td> <td>   15.341</td> <td> 0.000</td> <td>    1.850</td> <td>    2.392</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x4</th>        <td>    0.0196</td> <td>    0.003</td> <td>    7.650</td> <td> 0.000</td> <td>    0.015</td> <td>    0.025</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x6</th>        <td>    0.0082</td> <td>    0.001</td> <td>    9.713</td> <td> 0.000</td> <td>    0.007</td> <td>    0.010</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x7</th>        <td>   -0.0021</td> <td>    0.000</td> <td>   -5.716</td> <td> 0.000</td> <td>   -0.003</td> <td>   -0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x11</th>       <td>    0.3456</td> <td>    0.011</td> <td>   31.949</td> <td> 0.000</td> <td>    0.324</td> <td>    0.367</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>111.670</td> <th>  Durbin-Watson:     </th> <td>   1.647</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td> 252.156</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.026</td>  <th>  Prob(JB):          </th> <td>1.76e-55</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 4.110</td>  <th>  Cond. No.          </th> <td>1.86e+03</td>\n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 1.86e+03. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.217\n",
       "Model:                            OLS   Adj. R-squared:                  0.216\n",
       "Method:                 Least Squares   F-statistic:                     339.1\n",
       "Date:                Tue, 27 Aug 2019   Prob (F-statistic):          5.31e-258\n",
       "Time:                        08:09:07   Log-Likelihood:                -5755.3\n",
       "No. Observations:                4898   AIC:                         1.152e+04\n",
       "Df Residuals:                    4893   BIC:                         1.155e+04\n",
       "Df Model:                           4                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept      2.1214      0.138     15.341      0.000       1.850       2.392\n",
       "x4             0.0196      0.003      7.650      0.000       0.015       0.025\n",
       "x6             0.0082      0.001      9.713      0.000       0.007       0.010\n",
       "x7            -0.0021      0.000     -5.716      0.000      -0.003      -0.001\n",
       "x11            0.3456      0.011     31.949      0.000       0.324       0.367\n",
       "==============================================================================\n",
       "Omnibus:                      111.670   Durbin-Watson:                   1.647\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              252.156\n",
       "Skew:                           0.026   Prob(JB):                     1.76e-55\n",
       "Kurtosis:                       4.110   Cond. No.                     1.86e+03\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 1.86e+03. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smf.ols(\"y~x4+x6+x7+x11\", data=white).fit().summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 6.55199613e-02 -1.86317709e+00  2.20902007e-02  8.14828026e-02\n",
      " -2.47276537e-01  3.73276519e-03 -2.85747419e-04 -1.50284181e+02\n",
      "  6.86343742e-01  6.31476473e-01  1.93475697e-01]\n"
     ]
    }
   ],
   "source": [
    " # sklearn package\n",
    "lrm = LinearRegression(n_jobs=-1)     # 입력값형식: array-like(dataframe), matrix\n",
    "# 옵션: fit_intercept = True, normalize=False, n_jobs=-1 ⇨ all CPUs are used\n",
    "lrm.fit(X,y)\n",
    "print(lrm.coef_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "147.5394357375611 [ 8.00846101e-02 -1.70374343e+00  5.69767648e-02  8.17351234e-02\n",
      " -1.64381383e-02  4.96141486e-03 -4.74149230e-04 -1.48223181e+02\n",
      "  7.49786197e-01  7.33900620e-01  2.08766177e-01]\n"
     ]
    }
   ],
   "source": [
    "lrm.fit(X_train, y_train)\n",
    "print(lrm.intercept_ , lrm.coef_ )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6.13867211 4.87485387 5.80282258 ... 5.75952191 6.1982174  5.35556207]\n"
     ]
    }
   ],
   "source": [
    "# 예측값\n",
    "forecast = lrm.predict(X_test)\n",
    "print(forecast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5679515772489931"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MSE\n",
    "mean_squared_error(y_test,forecast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.135011905022889 [-0.         -0.          0.          0.00658765 -0.          0.00931903\n",
      " -0.0026721  -0.          0.          0.          0.26000292]\n"
     ]
    }
   ],
   "source": [
    "## LASSO, Ridge \n",
    "lasso = Lasso(alpha=0.1); ridge = Ridge(alpha=0.1)  # alpha=0: OLS\n",
    "lasso.fit(X_train, y_train)\n",
    "print(lasso.intercept_ , lasso.coef_ )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5.98542298 5.39795764 5.75828732 5.94075017 6.3486235  6.35493312\n",
      " 5.74667097 6.083002   5.67070478 5.79674228]\n"
     ]
    }
   ],
   "source": [
    "forecast = lasso.predict(X_test[0:10,])\n",
    "print(forecast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.78552166 0.78552166 0.78552166 0.78552166 0.78552166]\n",
      " [0.80186213 0.80186213 0.80186213 0.80186213 0.80186213]\n",
      " [0.81248145 0.81248145 0.81248145 0.81248145 0.81248145]\n",
      " [0.74349976 0.74349976 0.74349976 0.74349976 0.74349976]\n",
      " [0.75027438 0.75027438 0.75027438 0.75027438 0.75027438]\n",
      " [0.81594542 0.81594542 0.81594542 0.81594542 0.81594542]\n",
      " [0.81258628 0.81258628 0.81258628 0.81258628 0.81258628]\n",
      " [0.80037357 0.80037357 0.80037357 0.80037357 0.80037357]\n",
      " [0.75587781 0.75587781 0.75587781 0.75587781 0.75587781]\n",
      " [0.80144995 0.80144995 0.80144995 0.80144995 0.80144995]]\n"
     ]
    }
   ],
   "source": [
    "## training-validation procedure(반복 with train-test-split)\n",
    "result = np.zeros((10,5))\n",
    "a = [0.01, 0.02, 0.03, 0.04, 0.05]\n",
    "for step in range(10):\n",
    "    X0, X1, y0, y1 = train_test_split(X, y, test_size=0.3)\n",
    "    for choice in range(len(a)):\n",
    "        lasso = Lasso(alpha=a[choice], normalize=True)\n",
    "         # sklearn.preprocessing.StandardScaler\n",
    "        lasso.fit(X0, y0) \n",
    "        forecast = lasso.predict(X1)\n",
    "        result[step,choice] = mean_squared_error(y1,forecast)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow를 이용한 Regression analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.14.0'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# package 불러오기\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 읽기 및 분리\n",
    "xy = np.loadtxt('white.csv', skiprows=1, delimiter=',', dtype=np.float32)\n",
    "x_data = xy[:, 0:-1]\n",
    "y_data = xy[:, [-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 기존 그래프와 충돌방지\n",
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Build graph using tensorflow operations\n",
    "X = tf.placeholder(tf.float32, shape=[None, 11])\n",
    "Y = tf.placeholder(tf.float32, shape=[None, 1])\n",
    "W = tf.Variable(tf.random_normal([11, 1]), name='weight')\n",
    "b = tf.Variable(tf.random_normal([1]), name='bias')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear regression\n",
    "yhat = tf.matmul(X, W)+b\n",
    "cost = tf.reduce_mean(tf.square(yhat-Y))\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.001)   # AdamOptimizer\n",
    "train = optimizer.minimize(cost)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Cost:  42038.516 \n",
      "Prediction:\n",
      " [[-234.76195]\n",
      " [-162.94432]\n",
      " [-143.65971]\n",
      " ...\n",
      " [-155.78502]\n",
      " [-150.3809 ]\n",
      " [-138.19211]]\n",
      "500 Cost:  nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " ...\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "1000 Cost:  nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " ...\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "1500 Cost:  nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " ...\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "2000 Cost:  nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " ...\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n"
     ]
    }
   ],
   "source": [
    "## feed data and run graph & update variables in the graph\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "for step in range(2001):\n",
    "    cost_val, Yhat_val, _ = sess.run([cost, yhat, train], feed_dict={X: x_data, Y: y_data})\n",
    "    if step % 500 == 0:\n",
    "        print(step, \"Cost: \", cost_val, \"\\nPrediction:\\n\", Yhat_val)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 자료의 표준화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def minmaxscaler(data):\n",
    "    numerator = data - np.min(data, 0)\n",
    "    denominator = np.max(data, 0) - np.min(data, 0)\n",
    "    return numerator / denominator           \n",
    "    # noise term prevents the zero division:  (denominator + 1e-7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min(Y)= 3.0 \tmax(Y)= 9.0\n",
      "min(Y_s)= 0.0 \tmax(Y_s)= 1.0\n"
     ]
    }
   ],
   "source": [
    "ymax, ymin = np.max(y_data), np.min(y_data)\n",
    "print(\"min(Y)=\",ymin,\"\\tmax(Y)=\",ymax)\n",
    "xy_scale = minmaxscaler(xy)\n",
    "x_data = xy_scale[:, 0:-1]\n",
    "y_data = xy_scale[:, [-1]]\n",
    "print(\"min(Y_s)=\",np.min(y_data),\"\\tmax(Y_s)=\",np.max(y_data))\n",
    "X_train, X_test, y_train, y_test = train_test_split(x_data, y_data, test_size=0.3, random_state=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Cost:  2.9465487 \n",
      "Prediction:\n",
      " [[-1.02705  ]\n",
      " [-1.5177876]\n",
      " [-1.7397369]\n",
      " ...\n",
      " [-1.3423736]\n",
      " [-1.1197066]\n",
      " [-0.9458568]]\n",
      "1000 Cost:  0.11462104 \n",
      "Prediction:\n",
      " [[ 0.5639404 ]\n",
      " [ 0.04148901]\n",
      " [-0.09560657]\n",
      " ...\n",
      " [ 0.41319305]\n",
      " [ 0.4259554 ]\n",
      " [ 0.5983192 ]]\n",
      "2000 Cost:  0.10594891 \n",
      "Prediction:\n",
      " [[ 0.60472345]\n",
      " [ 0.09236348]\n",
      " [-0.03233176]\n",
      " ...\n",
      " [ 0.46460783]\n",
      " [ 0.47732723]\n",
      " [ 0.63539803]]\n",
      "3000 Cost:  0.100400925 \n",
      "Prediction:\n",
      " [[ 0.599861  ]\n",
      " [ 0.09866679]\n",
      " [-0.01707309]\n",
      " ...\n",
      " [ 0.46563655]\n",
      " [ 0.48347318]\n",
      " [ 0.6285032 ]]\n",
      "4000 Cost:  0.095396675 \n",
      "Prediction:\n",
      " [[ 0.5940834 ]\n",
      " [ 0.10391325]\n",
      " [-0.00413895]\n",
      " ...\n",
      " [ 0.46545482]\n",
      " [ 0.48757726]\n",
      " [ 0.6210936 ]]\n",
      "5000 Cost:  0.09086338 \n",
      "Prediction:\n",
      " [[0.5886856 ]\n",
      " [0.10936081]\n",
      " [0.00790536]\n",
      " ...\n",
      " [0.46549073]\n",
      " [0.4909888 ]\n",
      " [0.6143923 ]]\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "for step in range(5001):\n",
    "    cost_val, Yhat_val, _ = sess.run([cost, yhat, train], feed_dict={X: X_train, Y: y_train})\n",
    "    if step % 1000 == 0:\n",
    "        print(step, \"Cost: \", cost_val, \"\\nPrediction:\\n\", Yhat_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weight\n",
      " [[-0.08774281]\n",
      " [ 0.55103487]\n",
      " [-0.76723397]\n",
      " [ 1.3000622 ]\n",
      " [ 0.776293  ]\n",
      " [-1.7641325 ]\n",
      " [-0.979566  ]\n",
      " [-0.7604278 ]\n",
      " [-1.0477983 ]\n",
      " [ 0.7439249 ]\n",
      " [ 0.5664805 ]] \n",
      "bias: [0.93513066]\n"
     ]
    }
   ],
   "source": [
    "#표준화된 데이터의 weights, bias 추정 \n",
    "print(\"Weight\\n\",sess.run(W), \"\\nbias:\",sess.run(b))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.07211995]\n",
      " [ 0.45860177]\n",
      " [ 1.7565773 ]\n",
      " [-0.06336594]\n",
      " [-0.4881277 ]\n",
      " [ 1.0800716 ]\n",
      " [ 0.3068061 ]\n",
      " [-2.3012044 ]\n",
      " [-0.7123053 ]\n",
      " [ 2.100865  ]]\n",
      "3.4031768\n"
     ]
    }
   ],
   "source": [
    "# 예측 & MSE\n",
    "yhat = sess.run(yhat, feed_dict={X: X_test})\n",
    "resid = (ymax-ymin)*(y_test-yhat)\n",
    "print(resid[0:10])\n",
    "print(sess.run(tf.reduce_mean(tf.square(resid))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow를 이용한 기본적인 Neural Network 모형"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "# Neural Network 설정\n",
    "def multilayer_perceptron1(x, weights, biases):\n",
    "    layer_1 = tf.add(tf.matmul(x, weights['h1']), biases['b1'])\n",
    "    layer_1 = tf.nn.relu(layer_1)\n",
    "    out_layer = tf.matmul(layer_1, weights['out']) + biases['out']\n",
    "    return out_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Build graph using tensorflow operations\n",
    "n_hidden_1 = 36\n",
    "n_input = X_train.shape[1]\n",
    "X = tf.placeholder(tf.float32, shape=[None, n_input])\n",
    "Y = tf.placeholder(tf.float32, shape=[None, 1])\n",
    "W = {\n",
    "    'h1': tf.Variable(tf.random_normal([n_input, n_hidden_1])),\n",
    "    'out': tf.Variable(tf.random_normal([n_hidden_1, n_input]))\n",
    "}\n",
    "\n",
    "B = {\n",
    "    'b1': tf.Variable(tf.random_normal([n_hidden_1])),\n",
    "    'out': tf.Variable(tf.random_normal([1]))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear regression\n",
    "yhat = multilayer_perceptron1(X, W, B)   #\n",
    "cost = tf.reduce_mean(tf.square(yhat-Y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=0.01)\n",
    "train = optimizer.minimize(cost)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Cost: 22.076042 \n",
      "\n",
      "2000 Cost: 0.0155729465 \n",
      "\n",
      "4000 Cost: 0.014663008 \n",
      "\n",
      "6000 Cost: 0.015056234 \n",
      "\n",
      "8000 Cost: 0.014225225 \n",
      "\n",
      "10000 Cost: 0.0138367 \n",
      "\n",
      "12000 Cost: 0.0137619795 \n",
      "\n",
      "14000 Cost: 0.013913987 \n",
      "\n",
      "16000 Cost: 0.013791496 \n",
      "\n",
      "18000 Cost: 0.013703878 \n",
      "\n",
      "20000 Cost: 0.013778016 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "for step in range(20001):\n",
    "    cost_val, _ = sess.run([cost, train], feed_dict={X: X_train, Y: y_train})\n",
    "    if step % 2000 == 0:\n",
    "        print(step, \"Cost:\", cost_val, \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weight\n",
      " {'h1': array([[ 4.19410586e-01, -1.29329908e+00, -1.43222654e+00,\n",
      "         5.95965326e-01, -4.17102516e-01, -1.14486468e+00,\n",
      "         8.41097534e-02,  8.58534753e-01,  4.66499329e-01,\n",
      "         1.36269897e-01, -8.61387253e-01, -7.80033946e-01,\n",
      "        -1.03109860e+00,  1.17636347e+00, -8.51799965e-01,\n",
      "         1.01564395e+00,  4.39494997e-01,  2.58049160e-01,\n",
      "         8.86769116e-01, -1.11942363e+00,  5.61374903e-01,\n",
      "         7.32633770e-01,  8.92332733e-01,  2.68417001e-01,\n",
      "        -8.13811898e-01, -7.72404909e-01,  2.60366142e-01,\n",
      "        -1.17118299e+00, -4.58491564e-01, -9.21143115e-01,\n",
      "         1.53175527e-02, -1.24713731e+00, -1.02711463e+00,\n",
      "        -3.57367098e-01, -1.64141953e-01,  2.66056746e-01],\n",
      "       [-3.44580114e-02,  1.17931354e+00,  2.33103919e+00,\n",
      "         1.37720382e+00, -1.48696482e+00,  1.00773346e+00,\n",
      "         1.06010807e+00, -1.41633525e-01,  1.95311296e+00,\n",
      "         1.69636035e+00, -1.33969641e+00, -8.37248504e-01,\n",
      "         8.35343264e-03,  1.12940311e+00, -6.89633250e-01,\n",
      "         1.82375506e-01, -3.65818083e-01, -1.14015698e+00,\n",
      "        -4.90726441e-01, -3.18118304e-01,  3.19751501e+00,\n",
      "         2.90249348e-01, -1.02711570e+00,  8.18794608e-01,\n",
      "         9.69362915e-01,  5.47508756e-03, -4.68885452e-01,\n",
      "        -1.94858670e+00,  1.71066809e+00, -9.88019288e-01,\n",
      "        -7.92847335e-01, -2.81455874e-01, -7.61431098e-01,\n",
      "        -9.96203542e-01,  1.96162677e+00,  1.14101994e+00],\n",
      "       [ 2.34827828e-02,  2.76822478e-01,  5.21515429e-01,\n",
      "         5.17841518e-01, -1.38324344e+00,  2.03099990e+00,\n",
      "        -5.07820189e-01,  8.09261799e-01,  1.00595224e+00,\n",
      "         6.62289798e-01, -9.13243234e-01, -1.63152635e-01,\n",
      "         1.18214861e-01,  7.56775320e-01,  5.31753451e-02,\n",
      "         7.77079072e-03, -3.60215276e-01,  1.37939513e+00,\n",
      "        -1.71106737e-02, -1.23509072e-01,  1.36467886e+00,\n",
      "         5.62655270e-01,  1.60906881e-01,  3.63840699e-01,\n",
      "         4.96609092e-01,  8.80483985e-02,  4.57322091e-01,\n",
      "         1.43611181e+00,  9.87592280e-01, -4.93605614e-01,\n",
      "        -5.86669326e-01,  1.91985071e+00,  3.34582120e-01,\n",
      "         2.13339850e-01,  1.21387713e-01,  1.78808182e-01],\n",
      "       [-6.01525784e-01,  1.21217132e+00, -3.67993027e-01,\n",
      "        -7.49915302e-01,  1.60448098e+00,  7.46712685e-02,\n",
      "         1.43488395e+00,  4.73790705e-01,  4.16882664e-01,\n",
      "         5.01448989e-01, -6.76578403e-01,  3.68533134e-01,\n",
      "         5.61189532e-01,  2.19047570e+00, -6.74187183e-01,\n",
      "         1.37492925e-01, -1.35513648e-01,  5.08158863e-01,\n",
      "        -1.01714790e+00, -9.11683142e-01,  2.06112310e-01,\n",
      "        -1.26989269e+00,  1.47757137e+00, -2.89073795e-01,\n",
      "         1.56760633e+00,  4.12573546e-01,  5.25774896e-01,\n",
      "         1.23317873e+00,  2.99216241e-01, -4.77392860e-02,\n",
      "         1.16644168e+00,  7.25638471e-04,  6.20830238e-01,\n",
      "        -1.65619826e+00, -1.79163650e-01,  5.04318953e-01],\n",
      "       [-6.57209098e-01, -1.74563497e-01, -4.82153326e-01,\n",
      "        -7.80522525e-02, -1.16905820e+00,  6.53259158e-01,\n",
      "        -1.73895240e+00,  1.21930465e-01,  1.15130091e+00,\n",
      "        -8.21900904e-01, -2.48572206e+00,  1.28958380e+00,\n",
      "         6.67837039e-02,  8.46013352e-02,  7.36758828e-01,\n",
      "         3.86986732e-01,  9.49849546e-01,  4.40023720e-01,\n",
      "         8.17734420e-01,  4.81915146e-01,  1.64983058e+00,\n",
      "         4.39686149e-01, -9.15930629e-01, -4.07086909e-01,\n",
      "        -8.63939822e-01,  5.21413423e-02,  1.57395530e+00,\n",
      "         1.42559028e+00,  2.63551414e-01, -2.80126309e+00,\n",
      "        -1.79381177e-01, -1.32783759e+00,  1.85374275e-01,\n",
      "         5.84725738e-01, -7.83903301e-01,  6.72286749e-01],\n",
      "       [-1.92261708e+00, -9.52599883e-01,  1.04975140e+00,\n",
      "        -9.05747116e-01, -4.37785715e-01,  3.75529379e-01,\n",
      "         1.38723660e+00,  7.11960435e-01,  5.80245376e-01,\n",
      "         7.01095939e-01, -2.01499653e+00,  4.50095445e-01,\n",
      "         3.63165259e+00, -9.21369433e-01,  1.10258877e+00,\n",
      "         8.41302499e-02,  2.87129164e-01,  1.83550811e+00,\n",
      "        -1.71176827e+00, -1.25517142e+00,  1.17209029e+00,\n",
      "        -4.95793492e-01, -4.41119783e-02,  3.60586107e-01,\n",
      "        -6.17963731e-01,  2.71013761e+00,  2.47744775e+00,\n",
      "        -4.27434415e-01, -1.23491430e+00, -1.28836882e+00,\n",
      "        -1.16824698e+00, -9.97636616e-01,  9.19176757e-01,\n",
      "        -2.06195354e+00,  1.77286589e+00, -9.21320617e-01],\n",
      "       [ 4.51779574e-01, -1.19532132e+00,  3.28148961e-01,\n",
      "         5.74410319e-01, -2.11957306e-01,  9.20106769e-02,\n",
      "        -1.28794864e-01,  1.52250636e+00, -1.13151741e+00,\n",
      "        -9.94494021e-01,  1.18120039e+00,  1.08486128e+00,\n",
      "         6.53327644e-01,  1.03112876e+00,  3.58288825e-01,\n",
      "         4.45847392e-01, -2.35240057e-01,  4.00808245e-01,\n",
      "        -1.57948339e+00,  1.79294243e-01, -8.51280570e-01,\n",
      "         8.96742702e-01, -1.14097321e+00,  5.66327088e-02,\n",
      "         3.46349269e-01,  4.84056115e-01,  1.42702639e+00,\n",
      "        -4.00175035e-01, -1.29555464e-01,  4.96713400e-01,\n",
      "         2.05397055e-01,  3.32861960e-01, -7.37808883e-01,\n",
      "        -1.53976113e-01, -4.60121751e-01, -6.22669041e-01],\n",
      "       [ 8.05987954e-01, -4.15385991e-01, -1.12270162e-01,\n",
      "         1.14075351e+00, -7.32592344e-02,  1.75463781e-01,\n",
      "        -1.09487534e-01, -6.26948118e-01, -1.08760083e+00,\n",
      "        -1.45988774e+00, -7.96705931e-02, -1.35738146e+00,\n",
      "        -6.34309530e-01,  1.07355487e+00, -7.55265474e-01,\n",
      "         1.77904010e+00,  4.84121144e-01,  4.85428721e-01,\n",
      "        -4.90645468e-02, -1.05024195e+00, -3.46380174e-01,\n",
      "         1.78147126e-02, -1.89829755e+00, -2.65829891e-01,\n",
      "         9.60011303e-01, -4.55853820e-01,  5.57772934e-01,\n",
      "         8.25485826e-01, -5.47687352e-01, -7.42513120e-01,\n",
      "         1.28026199e+00, -3.43959481e-01, -9.11684513e-01,\n",
      "         8.05189252e-01, -7.47253895e-01, -2.17847109e-01],\n",
      "       [ 6.59338176e-01, -8.40526342e-01, -7.91257441e-01,\n",
      "         1.29641652e+00, -1.28057516e+00,  3.15156519e-01,\n",
      "        -1.24999571e+00, -1.24415958e+00, -5.95204771e-01,\n",
      "         6.01549566e-01, -1.19505727e+00, -4.06678259e-01,\n",
      "        -1.34828493e-01, -1.99482068e-01,  1.49053290e-01,\n",
      "         1.04270780e+00,  5.90944171e-01,  9.41982195e-02,\n",
      "        -1.41707480e+00,  1.21849261e-01,  1.07970327e-01,\n",
      "         6.65340304e-01,  4.85230722e-02,  4.29018885e-01,\n",
      "        -3.93316001e-01, -1.01662941e-01,  3.99431400e-02,\n",
      "        -3.57703567e+00, -2.36870244e-01,  3.00716162e-01,\n",
      "         1.29601419e-01, -5.39754748e-01, -2.61032701e-01,\n",
      "        -1.47172451e+00, -1.53437078e+00,  9.01453495e-01],\n",
      "       [ 3.62040997e-01, -3.02410331e-02, -9.21535850e-01,\n",
      "         2.20220447e-01,  1.91468120e+00, -8.59647453e-01,\n",
      "        -1.22468245e+00, -3.98749471e-01,  1.09794390e+00,\n",
      "         3.37756246e-01, -1.00783908e+00, -1.36733711e-01,\n",
      "        -2.58467615e-01,  2.37569600e-01,  7.33098269e-01,\n",
      "        -5.29931664e-01, -7.49352634e-01, -1.16949952e+00,\n",
      "        -6.06833026e-02,  3.67837876e-01,  7.13831663e-01,\n",
      "         1.32676911e+00,  8.60182941e-01, -1.16400230e+00,\n",
      "         1.41119465e-01, -1.94790676e-01,  6.06966019e-01,\n",
      "         1.00194097e+00,  1.34748828e+00, -1.44023907e+00,\n",
      "        -1.16336668e+00,  6.35525048e-01, -4.69087899e-01,\n",
      "        -2.26280785e+00,  2.86709338e-01,  2.73621917e-01],\n",
      "       [ 6.46297783e-02,  1.23429060e+00, -7.39643097e-01,\n",
      "         4.98999745e-01, -9.33686912e-01, -7.96450675e-01,\n",
      "         1.61191297e+00, -2.60026741e+00, -2.64052212e-01,\n",
      "         8.68701637e-01, -7.86221698e-02,  3.04979265e-01,\n",
      "        -9.40235257e-02,  3.59125361e-02,  5.93803823e-01,\n",
      "        -8.15398276e-01, -1.25839305e+00, -8.77894461e-02,\n",
      "        -3.09418821e+00,  7.49860287e-01,  2.25853190e-01,\n",
      "         2.37369388e-02,  5.87188065e-01,  7.22087562e-01,\n",
      "         1.93408728e+00, -6.81996420e-02,  3.13015819e-01,\n",
      "         8.66130650e-01,  1.37330556e+00,  8.87232065e-01,\n",
      "        -4.97570008e-01, -6.77307844e-01,  2.36529991e-01,\n",
      "        -3.92653918e+00,  6.75170720e-01, -1.28578782e-01]], dtype=float32), 'out': array([[-1.618498  , -1.1936866 , -0.77315056, -0.13674031, -0.46066564,\n",
      "         0.8616581 ,  1.5103314 , -0.16474065, -0.88726974,  0.60961837,\n",
      "        -1.046381  ],\n",
      "       [-1.1707577 , -0.30640578, -0.09771507, -2.0570078 , -0.15829529,\n",
      "        -1.145888  ,  0.9819945 ,  0.47859377, -0.76059276, -0.4541804 ,\n",
      "        -1.1700529 ],\n",
      "       [ 1.2923514 ,  0.38396573,  0.53092974,  0.00318471, -0.03136173,\n",
      "        -1.5878578 , -1.1701294 ,  0.16265571,  0.11380982,  2.155136  ,\n",
      "        -0.37035307],\n",
      "       [ 1.1932998 ,  0.12443209, -0.24104562, -0.4208861 , -0.34638456,\n",
      "        -0.71613675, -1.00936   , -0.6867714 , -0.946066  , -0.96543336,\n",
      "        -0.2317597 ],\n",
      "       [ 0.2171547 ,  0.650718  , -0.5256413 , -0.9319071 ,  0.8884112 ,\n",
      "        -0.36302724, -0.8753869 ,  0.7436049 ,  1.6070129 , -0.11575621,\n",
      "        -1.0432857 ],\n",
      "       [ 0.4943348 , -0.47294158,  1.3810469 , -0.9568612 , -1.2114325 ,\n",
      "         0.6013046 ,  2.0149374 ,  1.3874956 , -0.20623486, -0.27813387,\n",
      "        -2.0487328 ],\n",
      "       [-1.1401491 , -1.1450067 , -1.136515  , -1.1431147 , -1.1395985 ,\n",
      "        -1.1385478 , -1.1424994 , -1.1359879 , -1.1418095 , -1.1408672 ,\n",
      "        -1.1358632 ],\n",
      "       [-0.54819256, -1.310603  ,  0.4245102 ,  0.2997292 ,  2.1387668 ,\n",
      "        -0.09615763,  0.650302  ,  1.5448377 ,  0.6319672 , -0.10243528,\n",
      "        -0.35680622],\n",
      "       [ 1.7373052 ,  1.2281011 ,  0.02947163,  0.86240995,  0.11994395,\n",
      "         0.52367944,  0.17121832, -0.67191786,  0.13613914,  0.15133595,\n",
      "        -0.47726804],\n",
      "       [ 0.84259534,  0.8676417 ,  0.8658364 ,  0.86950445,  0.8824716 ,\n",
      "         0.87052166,  0.8748834 ,  0.87099254,  0.8760098 ,  0.8799521 ,\n",
      "         0.86436814],\n",
      "       [-1.0274612 ,  2.2224574 ,  0.8256297 , -1.2539567 ,  0.87844324,\n",
      "         0.73524696,  1.2609763 ,  0.09937156,  0.31694692, -0.79863596,\n",
      "        -0.02751555],\n",
      "       [ 0.70280087,  0.8142018 , -0.22968943,  0.6497918 ,  0.57119226,\n",
      "         0.62781537,  2.066256  ,  0.25601387, -0.40102434,  0.44485748,\n",
      "        -0.18278755],\n",
      "       [-0.80326045,  0.9937442 , -0.4134744 , -0.3938793 , -0.04647984,\n",
      "        -0.8801633 , -0.66866064, -0.8735864 ,  0.11256555,  0.62278336,\n",
      "         0.51339304],\n",
      "       [-0.48598844, -0.05337797,  1.090117  , -0.4698318 ,  0.09926157,\n",
      "         0.09163133, -0.26000622,  0.91292036,  1.0271223 ,  0.536583  ,\n",
      "         0.4558175 ],\n",
      "       [ 0.30332556, -0.48156935,  0.9054324 ,  0.22253384,  0.8882905 ,\n",
      "         0.9882018 , -0.05721865,  0.951739  ,  0.6265451 ,  0.6725262 ,\n",
      "         0.84034616],\n",
      "       [-0.67321044,  0.36941618, -0.4315847 , -0.048828  ,  0.73906845,\n",
      "         0.34781718,  1.9070284 ,  0.3481583 ,  1.1906935 ,  0.32780504,\n",
      "        -1.1666358 ],\n",
      "       [ 0.33049187,  1.861682  ,  0.5301536 ,  0.5168383 , -1.2533487 ,\n",
      "        -0.6250144 ,  0.8674162 ,  0.02224403, -0.63828367,  0.47945353,\n",
      "         0.69979   ],\n",
      "       [-0.7054712 , -0.41284624, -0.49098125, -0.7709151 , -0.0511823 ,\n",
      "         0.966228  ,  1.7484835 ,  1.4686772 ,  1.44126   ,  0.06703369,\n",
      "         0.03578847],\n",
      "       [ 0.64418197,  0.2086966 , -0.09315556, -0.24183987,  0.2193047 ,\n",
      "         1.2106768 ,  0.6347329 ,  0.11843758,  0.24119551,  0.2493385 ,\n",
      "        -0.29027745],\n",
      "       [-0.6574992 , -0.08140998,  0.63258415, -0.23955475, -0.3800995 ,\n",
      "        -0.02661958, -1.5102473 , -0.1416941 ,  1.6593953 ,  0.27055314,\n",
      "        -0.28857365],\n",
      "       [-1.3632574 , -1.6859088 , -0.14170218, -0.35810116,  0.00445727,\n",
      "         0.32690406, -0.8754152 ,  0.09706051, -0.08953   ,  0.09496041,\n",
      "         0.16194628],\n",
      "       [ 0.4935443 ,  0.87482554,  0.5464824 , -0.6037031 ,  0.23278695,\n",
      "        -0.79643565, -0.06163235,  0.32863364, -0.3561187 , -0.13940577,\n",
      "         0.2618619 ],\n",
      "       [-0.75538266, -1.1096066 , -0.17822333,  0.13176802,  0.12528361,\n",
      "        -0.871857  ,  0.22506616,  0.622068  ,  1.9392991 ,  0.88551605,\n",
      "         1.8564749 ],\n",
      "       [ 0.82545835, -0.16299282, -0.6153387 ,  0.2466903 , -0.41321516,\n",
      "         0.46767926, -1.1888955 , -1.145271  , -1.4761637 , -0.20516665,\n",
      "         0.23522411],\n",
      "       [ 0.7430829 ,  1.5398619 ,  0.262796  ,  1.0217022 , -0.56148404,\n",
      "         0.2579728 ,  0.3864679 , -0.4838084 ,  0.06824611,  0.6382028 ,\n",
      "         0.05482373],\n",
      "       [ 0.60480356, -1.7949531 ,  0.08657407,  0.06222638, -0.39901772,\n",
      "         0.7099656 ,  0.42703477,  0.7003764 , -0.6202056 , -1.2989116 ,\n",
      "        -1.1573652 ],\n",
      "       [-0.39992023, -0.43591666, -0.42117524, -0.41977194, -0.4381572 ,\n",
      "        -0.41582656, -0.41216812, -0.41986936, -0.4175047 , -0.43186763,\n",
      "        -0.41757676],\n",
      "       [ 0.6006168 ,  1.6730515 ,  1.4244462 , -1.7283567 , -0.01515309,\n",
      "        -1.5078243 ,  0.70513725,  0.25158146, -0.1658697 ,  1.527065  ,\n",
      "        -0.13729735],\n",
      "       [ 0.33010775, -0.14199841, -1.0281975 ,  1.0075653 ,  0.05049151,\n",
      "        -0.16779995,  0.17225562, -0.358062  , -0.47819132, -0.6647721 ,\n",
      "         0.7672351 ],\n",
      "       [-0.8130239 , -0.27063966, -1.1270405 , -0.0699095 ,  0.08642025,\n",
      "         2.475266  , -1.0465184 , -0.7609274 , -0.37525544,  2.0938733 ,\n",
      "         0.21005858],\n",
      "       [ 1.4584434 , -1.0327486 , -0.03114472,  0.68259263,  0.9988548 ,\n",
      "         0.56623864, -2.2002559 , -0.35236558, -0.28935602, -0.54977715,\n",
      "         1.1103765 ],\n",
      "       [ 1.5956827 ,  1.7773795 , -0.17348276,  1.3507364 ,  0.40445068,\n",
      "        -0.9827377 ,  0.80318546, -0.13788156, -1.1406941 , -0.87301767,\n",
      "         0.3653961 ],\n",
      "       [-0.09770236,  0.09799068, -1.1803521 , -0.7019082 ,  0.13828133,\n",
      "         0.4953717 , -0.34167877,  0.83614045, -0.72799027, -0.74236065,\n",
      "         2.198568  ],\n",
      "       [-1.1178639 , -1.0810225 , -1.0895449 , -1.0847054 , -1.094523  ,\n",
      "        -1.0819474 , -1.0607214 , -1.0793171 , -1.0711687 , -1.0731031 ,\n",
      "        -1.094722  ],\n",
      "       [-0.06593164, -0.05804552, -0.17940658, -1.0275879 ,  0.8245497 ,\n",
      "        -2.0953364 , -0.5457708 , -1.2168753 ,  0.4781683 ,  0.43191314,\n",
      "         1.1055686 ],\n",
      "       [ 0.96545726,  1.191528  , -0.23704769,  0.6189884 , -0.08169367,\n",
      "        -0.6287229 ,  0.75900376, -0.00288771, -0.7995897 , -0.35515893,\n",
      "         0.8170412 ]], dtype=float32)} \n",
      "bias: {'b1': array([ 0.42077097,  1.6198338 , -0.9225755 , -0.90892017, -0.14007238,\n",
      "       -1.2004657 , -1.3000702 , -0.9127983 ,  0.5317681 , -0.3307707 ,\n",
      "        0.8499223 ,  0.91869867, -0.02655211,  0.8991767 ,  0.42159298,\n",
      "        0.5686663 ,  1.5600035 , -1.314863  ,  0.56894237,  1.2411747 ,\n",
      "       -0.7222435 , -0.65150595, -1.3448921 , -2.7549977 , -0.05486123,\n",
      "       -0.02143829, -0.8837029 , -0.7236683 ,  0.7670978 , -0.36896697,\n",
      "        2.3053102 , -1.278974  ,  0.0588255 ,  1.7423955 , -3.0671492 ,\n",
      "       -1.3988873 ], dtype=float32), 'out': array([-0.7832166], dtype=float32)}\n"
     ]
    }
   ],
   "source": [
    "#표준화된 데이터의 weights, bias 추정 \n",
    "print(\"Weight\\n\",sess.run(W), \"\\nbias:\",sess.run(B))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.9748124   0.9749676   1.0407797   0.99456775  1.0411931   1.0732845\n",
      "   1.0893363   1.0949024   1.0720772   1.0513047   0.9991411 ]\n",
      " [ 0.16777807  0.17226487  0.2401455   0.19505721  0.2419079   0.27553707\n",
      "   0.289604    0.2948497   0.27555066  0.2555521   0.20022422]\n",
      " [ 0.3005991   0.29644704  0.36957836  0.32541704  0.37484694  0.4083817\n",
      "   0.42720294  0.43027854  0.39591622  0.37518668  0.31191015]\n",
      " [-0.2414875  -0.22047186 -0.16719389 -0.21001697 -0.16171288 -0.13442874\n",
      "  -0.11152339 -0.11352253 -0.1295929  -0.14520836 -0.20868802]\n",
      " [-0.7327781  -0.7357435  -0.6667607  -0.7080796  -0.66248345 -0.6308005\n",
      "  -0.6128819  -0.61079836 -0.6409972  -0.66017246 -0.721575  ]\n",
      " [-0.77144766 -0.77675843 -0.7079036  -0.7497704  -0.70590377 -0.6717632\n",
      "  -0.6526344  -0.6512947  -0.6811502  -0.7025964  -0.7612202 ]\n",
      " [-0.15161347 -0.13369632 -0.07916808 -0.11996913 -0.0710392  -0.04790998\n",
      "  -0.02776551 -0.02780414 -0.04626489 -0.0603869  -0.12033391]\n",
      " [ 0.17530489  0.18348098  0.24464393  0.20121646  0.24436498  0.27751923\n",
      "   0.2949407   0.2982545   0.27974582  0.26066422  0.20759082]\n",
      " [ 0.45759988  0.47978425  0.5287986   0.49016047  0.5374539   0.55789804\n",
      "   0.5760648   0.57677794  0.56207156  0.5500853   0.49276614]\n",
      " [-0.14764667 -0.12943196 -0.07466483 -0.11481214 -0.0699842  -0.04142976\n",
      "  -0.01927972 -0.02201486 -0.03778696 -0.05438519 -0.11466622]]\n",
      "0.5335518\n"
     ]
    }
   ],
   "source": [
    "# 예측 & MSE\n",
    "yhat = sess.run(yhat, feed_dict={X: X_test})\n",
    "resid = (ymax-ymin)*(y_test-yhat)\n",
    "print(resid[0:10])\n",
    "print(sess.run(tf.reduce_mean(tf.square(resid))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'E:/인권이라이프/강의실에서/외부강의/통계학회/기계학습과 딥러닝-실습/parameters.ckpt'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 학습결과(weights, biases) 저장 및 반환\n",
    "saver = tf.train.Saver()\n",
    "saver.save(sess, \"E:/인권이라이프/강의실에서/외부강의/통계학회/기계학습과 딥러닝-실습/parameters.ckpt\")      # 반환: saver.restore(sess, \"parameters.ckpt\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "# Layer가 2개로 구성된 NN\n",
    "def multilayer_perceptron2(X, W, B, Rate):\n",
    "    layer_1 = tf.add(tf.matmul(X, W['h1']), B['b1'])\n",
    "    layer_1 = tf.nn.relu(layer_1)\n",
    "    layer_1 = tf.nn.dropout(layer_1, rate=Rate)   ## rate = 1 - keep_prob : keep_prob는 이후 버전에서 제외될 예정\n",
    "    layer_2 = tf.add(tf.matmul(layer_1,W['h2']),B['b2'])\n",
    "    layer_2 = tf.nn.relu(layer_2)\n",
    "    layer_2 = tf.nn.dropout(layer_2, rate=Rate)\n",
    "    out_layer = tf.matmul(layer_2, W['out']) + B['out']\n",
    "    return out_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Build graph using tensorflow operations\n",
    "n_hidden_1 = 36\n",
    "n_hidden_2 = 36\n",
    "n_input = X_train.shape[1]\n",
    "Rate = tf.placeholder(\"float\")\n",
    "X = tf.placeholder(tf.float32, shape=[None, n_input])\n",
    "Y = tf.placeholder(tf.float32, shape=[None, 1])\n",
    "W = {\n",
    "    'h1': tf.Variable(tf.random_normal([n_input, n_hidden_1])),\n",
    "    'h2': tf.Variable(tf.random_normal([n_hidden_1, n_hidden_2])),\n",
    "    'out': tf.Variable(tf.random_normal([n_hidden_2, n_input]))\n",
    "}\n",
    "B = {\n",
    "    'b1': tf.Variable(tf.random_normal([n_hidden_1])),\n",
    "    'b2': tf.Variable(tf.random_normal([n_hidden_2])),\n",
    "    'out': tf.Variable(tf.random_normal([1]))\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat = multilayer_perceptron2(X, W, B, Rate)   #\n",
    "cost = tf.reduce_mean(tf.square(yhat-Y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=0.01)\n",
    "train = optimizer.minimize(cost)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Cost:  953.60516\n",
      "2000 Cost:  0.025460858\n",
      "4000 Cost:  0.022146514\n",
      "6000 Cost:  0.022438217\n",
      "8000 Cost:  0.022121524\n",
      "10000 Cost:  0.022121547\n",
      "12000 Cost:  0.022121524\n",
      "14000 Cost:  0.022121524\n",
      "16000 Cost:  0.022121526\n",
      "18000 Cost:  0.022121528\n",
      "20000 Cost:  0.022121532\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "for step in range(20001):\n",
    "    cost_val, _ = sess.run([cost, train], feed_dict={X: X_train, Y: y_train, Rate:0.2})\n",
    "    if step % 2000 == 0:\n",
    "        print(step, \"Cost: \", cost_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.755976\n"
     ]
    }
   ],
   "source": [
    "# 예측 & MSE\n",
    "yhat = sess.run(yhat, feed_dict={X: X_test, Rate: 0.0})\n",
    "resid = (ymax-ymin)*(y_test-yhat)\n",
    "print(sess.run(tf.reduce_mean(tf.square(resid))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split \n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "white = pd.read_csv(\"white.csv\")   # dataframe\n",
    "white = white[-np.isnan(white[\"y\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Logistic Regression()\n",
    "white[\"good\"] = (white.y > 5).astype(float)\n",
    "X = np.array(white.drop([\"y\",\"good\"],1))\n",
    "y_binary = np.array(white[\"good\"])\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_binary, test_size=0.3, random_state=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.508625\n",
      "         Iterations 8\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                 3428\n",
      "Model:                          Logit   Df Residuals:                     3416\n",
      "Method:                           MLE   Df Model:                           11\n",
      "Date:                Tue, 27 Aug 2019   Pseudo R-squ.:                  0.2100\n",
      "Time:                        08:16:03   Log-Likelihood:                -1743.6\n",
      "converged:                       True   LL-Null:                       -2206.9\n",
      "                                        LLR p-value:                1.101e-191\n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const        202.1746     77.031      2.625      0.009      51.196     353.153\n",
      "x1             0.0022      0.083      0.026      0.979      -0.160       0.164\n",
      "x2            -5.8583      0.487    -12.033      0.000      -6.813      -4.904\n",
      "x3             0.1649      0.371      0.445      0.657      -0.562       0.892\n",
      "x4             0.1498      0.030      4.962      0.000       0.091       0.209\n",
      "x5             0.9854      2.091      0.471      0.637      -3.113       5.083\n",
      "x6             0.0112      0.003      3.344      0.001       0.005       0.018\n",
      "x7            -0.0022      0.001     -1.564      0.118      -0.005       0.001\n",
      "x8          -215.0109     78.140     -2.752      0.006    -368.163     -61.859\n",
      "x9             1.0349      0.417      2.479      0.013       0.217       1.853\n",
      "x10            2.3811      0.434      5.481      0.000       1.530       3.233\n",
      "x11            0.8020      0.103      7.779      0.000       0.600       1.004\n",
      "==============================================================================\n"
     ]
    }
   ],
   "source": [
    "# statmodels\n",
    "logit_sm = sm.Logit(y_train, sm.add_constant(X_train)).fit()\n",
    "print(logit_sm.summary())     \n",
    "   # logit_sm.params, logit_sm.fittedvalues(=eta), \n",
    "   # logit_sm.model.cdf(eta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, ..., 1, 1, 0])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "muhat = logit_sm.predict(sm.add_constant(X_test))\n",
    "(muhat > 0.5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.540885\n",
      "         Iterations 6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Logit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>       <td>good</td>       <th>  No. Observations:  </th>   <td>  4898</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>               <td>Logit</td>      <th>  Df Residuals:      </th>   <td>  4893</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>               <td>MLE</td>       <th>  Df Model:          </th>   <td>     4</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>          <td>Tue, 27 Aug 2019</td> <th>  Pseudo R-squ.:     </th>   <td>0.1516</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>              <td>08:16:07</td>     <th>  Log-Likelihood:    </th>  <td> -2649.3</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>           <td>True</td>       <th>  LL-Null:           </th>  <td> -3122.7</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th> </th>                      <td> </td>        <th>  LLR p-value:       </th> <td>1.149e-203</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th> <td>   -9.3557</td> <td>    0.480</td> <td>  -19.491</td> <td> 0.000</td> <td>  -10.296</td> <td>   -8.415</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x4</th>        <td>    0.0549</td> <td>    0.008</td> <td>    7.112</td> <td> 0.000</td> <td>    0.040</td> <td>    0.070</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x6</th>        <td>    0.0204</td> <td>    0.003</td> <td>    7.875</td> <td> 0.000</td> <td>    0.015</td> <td>    0.025</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x7</th>        <td>   -0.0059</td> <td>    0.001</td> <td>   -5.604</td> <td> 0.000</td> <td>   -0.008</td> <td>   -0.004</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x11</th>       <td>    0.9520</td> <td>    0.041</td> <td>   23.311</td> <td> 0.000</td> <td>    0.872</td> <td>    1.032</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                           Logit Regression Results                           \n",
       "==============================================================================\n",
       "Dep. Variable:                   good   No. Observations:                 4898\n",
       "Model:                          Logit   Df Residuals:                     4893\n",
       "Method:                           MLE   Df Model:                            4\n",
       "Date:                Tue, 27 Aug 2019   Pseudo R-squ.:                  0.1516\n",
       "Time:                        08:16:07   Log-Likelihood:                -2649.3\n",
       "converged:                       True   LL-Null:                       -3122.7\n",
       "                                        LLR p-value:                1.149e-203\n",
       "==============================================================================\n",
       "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept     -9.3557      0.480    -19.491      0.000     -10.296      -8.415\n",
       "x4             0.0549      0.008      7.112      0.000       0.040       0.070\n",
       "x6             0.0204      0.003      7.875      0.000       0.015       0.025\n",
       "x7            -0.0059      0.001     -5.604      0.000      -0.008      -0.004\n",
       "x11            0.9520      0.041     23.311      0.000       0.872       1.032\n",
       "==============================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import statsmodels.formula.api as smf\n",
    "model = \"good ~ x4+x6+x7+x11\"\n",
    "logit_smf = smf.logit(formula=str(model),data=white).fit()\n",
    "logit_smf.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-2.54268734e-01 -4.99157207e+00  7.03080675e-02  5.69184252e-02\n",
      "  -5.18202072e-01  1.27063973e-02 -3.60579178e-03 -2.70489299e+00\n",
      "  -5.22530573e-01  1.73828318e+00  9.39603772e-01]] [-2.70554792]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\no1papa\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "#sklearn : “statsmodels” 결과와 다름\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "logitR = LogisticRegression()    \n",
    "logitR.fit(X_train, y_train, sample_weight=None)  \n",
    "print(logitR.coef_, logitR.intercept_)       # Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.11567848 0.88432152]\n",
      " [0.84644301 0.15355699]\n",
      " [0.3825212  0.6174788 ]\n",
      " ...\n",
      " [0.36193797 0.63806203]\n",
      " [0.14776534 0.85223466]\n",
      " [0.67675905 0.32324095]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\no1papa\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "logitL = LogisticRegression(penalty=\"l1\")  # LASSO , C = 1/alpha    \n",
    "logitL.fit(X_train, y_train, sample_weight=None)   \n",
    "muL = logitL.predict_proba(X_test)\n",
    "print(muL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 0. 1. ... 1. 1. 0.]\n"
     ]
    }
   ],
   "source": [
    "yhat = logitL.predict(X_test) \n",
    "print(yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[241 219]\n",
      " [152 858]]\n",
      "col_0  0.0  1.0\n",
      "row_0          \n",
      "0.0    241  219\n",
      "1.0    152  858\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "print(metrics.confusion_matrix(y_test, yhat))\n",
    "print(pd.crosstab(index=y_test,columns=yhat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2523809523809524\n"
     ]
    }
   ],
   "source": [
    "print(1-metrics.accuracy_score(y_test,yhat))  # 오분류율   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow를 이용한 Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "xy = np.loadtxt('white.csv',skiprows=1, delimiter=',', dtype=np.float32)\n",
    "y_binary = 1*(xy[:, [-1]] > 5)\n",
    "print(y_binary[0:5])\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler(); scaler.fit(xy); xy_scale = scaler.transform(xy)\n",
    "\n",
    "x_data = xy_scale[:, 0:-1]\n",
    "X_train, X_test, y_train, y_test = train_test_split(x_data, y_binary, test_size=0.3, random_state=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic regression\n",
    "X = tf.placeholder(tf.float32, shape=[None, 11])\n",
    "Y = tf.placeholder(tf.float32, shape=[None, 1])\n",
    "W = tf.Variable(tf.random_normal([11, 1]), name='weight')\n",
    "b = tf.Variable(tf.random_normal([1]), name='bias')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logit link\n",
    "mu = tf.sigmoid(tf.matmul(X, W) + b)    \n",
    "# - log-likelihood function\n",
    "cost = -tf.reduce_mean(Y*tf.log(mu)+(1-Y)*tf.log(1-mu)) \n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=0.01)  \n",
    "train = optimizer.minimize(cost)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = tf.cast(mu > 0.5, dtype=tf.float32)\n",
    "accuracy = tf.reduce_mean(tf.cast(tf.equal(predicted, Y), dtype=tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.6390258\n",
      "200 0.5486288\n",
      "400 0.5262918\n",
      "600 0.5167864\n",
      "800 0.5123126\n",
      "1000 0.510117\n",
      "1200 0.5090335\n",
      "1400 0.508509\n",
      "1600 0.5082584\n",
      "1800 0.508133\n",
      "2000 0.50805855\n",
      "\n",
      "Mu:  [[0.7713352 ]\n",
      " [0.9318801 ]\n",
      " [0.9562696 ]\n",
      " ...\n",
      " [0.8000567 ]\n",
      " [0.74424666]\n",
      " [0.34591797]] \n",
      "Predict(Y):  [[1.]\n",
      " [1.]\n",
      " [1.]\n",
      " ...\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]] \n",
      "Accuracy:  0.75714284\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for step in range(2001):\n",
    "        cost_val, _ = sess.run([cost, train],feed_dict={X: X_train, Y: y_train})\n",
    "        if step % 200 == 0:\n",
    "            print(step, cost_val)\n",
    "    h, c, a = sess.run([mu, predicted, accuracy], feed_dict={X: X_test, Y: y_test})\n",
    "print(\"\\nMu: \", h, \"\\nPredict(Y): \", c, \"\\nAccuracy: \", a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 다범주 로지스틱 모형"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import datasets   \n",
    "# iris data\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data[:, :4]; Y = iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: nan\n",
      "         Iterations 26\n",
      "                          MNLogit Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                  150\n",
      "Model:                        MNLogit   Df Residuals:                      140\n",
      "Method:                           MLE   Df Model:                            8\n",
      "Date:                Tue, 27 Aug 2019   Pseudo R-squ.:                     nan\n",
      "Time:                        08:21:13   Log-Likelihood:                    nan\n",
      "converged:                       True   LL-Null:                       -164.79\n",
      "                                        LLR p-value:                       nan\n",
      "==============================================================================\n",
      "       y=1       coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "x1                nan        nan        nan        nan         nan         nan\n",
      "x2                nan        nan        nan        nan         nan         nan\n",
      "x3                nan        nan        nan        nan         nan         nan\n",
      "x4                nan        nan        nan        nan         nan         nan\n",
      "const             nan        nan        nan        nan         nan         nan\n",
      "------------------------------------------------------------------------------\n",
      "       y=2       coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "x1                nan        nan        nan        nan         nan         nan\n",
      "x2                nan        nan        nan        nan         nan         nan\n",
      "x3                nan        nan        nan        nan         nan         nan\n",
      "x4                nan        nan        nan        nan         nan         nan\n",
      "const             nan        nan        nan        nan         nan         nan\n",
      "==============================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\no1papa\\Anaconda3\\lib\\site-packages\\statsmodels\\discrete\\discrete_model.py:2128: RuntimeWarning: invalid value encountered in true_divide\n",
      "  return eXB/eXB.sum(1)[:,None]\n",
      "C:\\Users\\no1papa\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\optimizer.py:271: RuntimeWarning: invalid value encountered in greater\n",
      "  oldparams) > tol)):\n",
      "C:\\Users\\no1papa\\Anaconda3\\lib\\site-packages\\scipy\\stats\\_distn_infrastructure.py:877: RuntimeWarning: invalid value encountered in greater\n",
      "  return (self.a < x) & (x < self.b)\n",
      "C:\\Users\\no1papa\\Anaconda3\\lib\\site-packages\\scipy\\stats\\_distn_infrastructure.py:877: RuntimeWarning: invalid value encountered in less\n",
      "  return (self.a < x) & (x < self.b)\n",
      "C:\\Users\\no1papa\\Anaconda3\\lib\\site-packages\\scipy\\stats\\_distn_infrastructure.py:1831: RuntimeWarning: invalid value encountered in less_equal\n",
      "  cond2 = cond0 & (x <= self.a)\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "X = sm.add_constant(X, prepend = False)\n",
    "mlogit_sm = sm.MNLogit(Y, X).fit(maxiter=100)\n",
    "print (mlogit_sm.summary())   # Perfect separation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.039662\n",
      "         Iterations: 65\n",
      "         Function evaluations: 67\n",
      "         Gradient evaluations: 67\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>MNLogit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>         <td>y</td>        <th>  No. Observations:  </th>  <td>   150</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>              <td>MNLogit</td>     <th>  Df Residuals:      </th>  <td>   140</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>               <td>MLE</td>       <th>  Df Model:          </th>  <td>     8</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>          <td>Tue, 27 Aug 2019</td> <th>  Pseudo R-squ.:     </th>  <td>0.9639</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>              <td>08:21:14</td>     <th>  Log-Likelihood:    </th> <td> -5.9493</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>           <td>True</td>       <th>  LL-Null:           </th> <td> -164.79</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th> </th>                      <td> </td>        <th>  LLR p-value:       </th> <td>7.055e-64</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "   <th>y=1</th>     <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>   -5.8833</td> <td>  6.7e+04</td> <td>-8.79e-05</td> <td> 1.000</td> <td>-1.31e+05</td> <td> 1.31e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>    <td>  -14.4150</td> <td> 4.54e+04</td> <td>   -0.000</td> <td> 1.000</td> <td> -8.9e+04</td> <td> 8.89e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3</th>    <td>   20.6480</td> <td> 8.03e+04</td> <td>    0.000</td> <td> 1.000</td> <td>-1.57e+05</td> <td> 1.57e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x4</th>    <td>    2.5831</td> <td> 1.34e+05</td> <td> 1.93e-05</td> <td> 1.000</td> <td>-2.63e+05</td> <td> 2.63e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>   17.6936</td> <td> 2.81e+05</td> <td> 6.29e-05</td> <td> 1.000</td> <td>-5.51e+05</td> <td> 5.51e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "   <th>y=2</th>     <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>   -8.3486</td> <td>  6.7e+04</td> <td>   -0.000</td> <td> 1.000</td> <td>-1.31e+05</td> <td> 1.31e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>    <td>  -21.0967</td> <td> 4.54e+04</td> <td>   -0.000</td> <td> 1.000</td> <td> -8.9e+04</td> <td> 8.89e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3</th>    <td>   30.0778</td> <td> 8.03e+04</td> <td>    0.000</td> <td> 1.000</td> <td>-1.57e+05</td> <td> 1.57e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x4</th>    <td>   20.8670</td> <td> 1.34e+05</td> <td>    0.000</td> <td> 1.000</td> <td>-2.63e+05</td> <td> 2.63e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>  -24.9395</td> <td> 2.81e+05</td> <td>-8.87e-05</td> <td> 1.000</td> <td>-5.51e+05</td> <td> 5.51e+05</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                          MNLogit Regression Results                          \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   No. Observations:                  150\n",
       "Model:                        MNLogit   Df Residuals:                      140\n",
       "Method:                           MLE   Df Model:                            8\n",
       "Date:                Tue, 27 Aug 2019   Pseudo R-squ.:                  0.9639\n",
       "Time:                        08:21:14   Log-Likelihood:                -5.9493\n",
       "converged:                       True   LL-Null:                       -164.79\n",
       "                                        LLR p-value:                 7.055e-64\n",
       "==============================================================================\n",
       "       y=1       coef    std err          z      P>|z|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "x1            -5.8833    6.7e+04  -8.79e-05      1.000   -1.31e+05    1.31e+05\n",
       "x2           -14.4150   4.54e+04     -0.000      1.000    -8.9e+04    8.89e+04\n",
       "x3            20.6480   8.03e+04      0.000      1.000   -1.57e+05    1.57e+05\n",
       "x4             2.5831   1.34e+05   1.93e-05      1.000   -2.63e+05    2.63e+05\n",
       "const         17.6936   2.81e+05   6.29e-05      1.000   -5.51e+05    5.51e+05\n",
       "------------------------------------------------------------------------------\n",
       "       y=2       coef    std err          z      P>|z|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "x1            -8.3486    6.7e+04     -0.000      1.000   -1.31e+05    1.31e+05\n",
       "x2           -21.0967   4.54e+04     -0.000      1.000    -8.9e+04    8.89e+04\n",
       "x3            30.0778   8.03e+04      0.000      1.000   -1.57e+05    1.57e+05\n",
       "x4            20.8670   1.34e+05      0.000      1.000   -2.63e+05    2.63e+05\n",
       "const        -24.9395   2.81e+05  -8.87e-05      1.000   -5.51e+05    5.51e+05\n",
       "==============================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlogit_sm = sm.MNLogit(Y, X).fit(method='bfgs',maxiter=100)\n",
    "mlogit_sm.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.00000000e+00 3.31700223e-15 5.12985000e-42]\n",
      " [1.00000000e+00 1.45187753e-11 1.03835955e-36]\n",
      " [1.00000000e+00 3.34307894e-13 4.00678382e-39]\n",
      " [1.00000000e+00 1.58178500e-10 3.11967289e-35]\n",
      " [1.00000000e+00 1.41325002e-15 1.43370189e-42]\n",
      " [1.00000000e+00 1.46097425e-15 4.88395046e-41]\n",
      " [1.00000000e+00 3.43952223e-13 2.21530066e-38]\n",
      " [1.00000000e+00 1.99075015e-13 1.97313854e-39]\n",
      " [9.99999999e-01 1.16278643e-09 5.56460301e-34]\n",
      " [1.00000000e+00 2.09143062e-11 3.16334940e-37]\n",
      " [1.00000000e+00 2.50545184e-16 1.24797562e-43]\n",
      " [1.00000000e+00 5.09050639e-12 2.12111730e-37]\n",
      " [1.00000000e+00 2.01955088e-11 2.96947458e-37]\n",
      " [1.00000000e+00 7.80910606e-13 2.32683771e-39]\n",
      " [1.00000000e+00 6.43525674e-22 9.51642706e-52]\n",
      " [1.00000000e+00 2.98188907e-21 2.55525503e-49]\n",
      " [1.00000000e+00 3.78201502e-19 2.90891022e-46]\n",
      " [1.00000000e+00 4.29465370e-15 4.13376945e-41]\n",
      " [1.00000000e+00 8.16530731e-16 4.08346277e-42]\n",
      " [1.00000000e+00 4.48286940e-16 1.49261826e-42]\n",
      " [1.00000000e+00 1.17610909e-12 2.86671356e-38]\n",
      " [1.00000000e+00 2.45342303e-15 9.91766836e-41]\n",
      " [1.00000000e+00 3.84882791e-18 2.40830602e-46]\n",
      " [1.00000000e+00 6.30304396e-11 1.51373067e-33]\n",
      " [9.99999998e-01 2.49431024e-09 1.75932221e-33]\n",
      " [9.99999999e-01 5.01051584e-10 1.84626820e-34]\n",
      " [1.00000000e+00 2.63094251e-12 2.59358798e-36]\n",
      " [1.00000000e+00 1.45200593e-14 4.50600286e-41]\n",
      " [1.00000000e+00 7.78524932e-15 1.83548345e-41]\n",
      " [1.00000000e+00 1.63808380e-10 3.32335405e-35]\n",
      " [1.00000000e+00 3.84470372e-10 1.18911106e-34]\n",
      " [1.00000000e+00 3.17214277e-14 4.54304465e-39]\n",
      " [1.00000000e+00 1.96599414e-18 1.77923950e-47]\n",
      " [1.00000000e+00 1.30761294e-20 7.01901564e-50]\n",
      " [1.00000000e+00 2.70785777e-11 2.54911101e-36]\n",
      " [1.00000000e+00 7.25930761e-15 1.61739229e-41]\n",
      " [1.00000000e+00 3.99932897e-17 8.98567460e-45]\n",
      " [1.00000000e+00 1.96582030e-15 4.10006469e-43]\n",
      " [1.00000000e+00 3.48928275e-11 3.33391643e-36]\n",
      " [1.00000000e+00 1.10537479e-13 8.56217586e-40]\n",
      " [1.00000000e+00 9.81082487e-16 4.70608162e-42]\n",
      " [9.99999395e-01 6.04851599e-07 3.02104578e-29]\n",
      " [1.00000000e+00 1.95284708e-12 4.90361337e-38]\n",
      " [1.00000000e+00 1.04337919e-12 2.04251338e-35]\n",
      " [1.00000000e+00 2.24211449e-12 2.01944147e-36]\n",
      " [1.00000000e+00 3.38547470e-11 1.92824752e-35]\n",
      " [1.00000000e+00 2.72962840e-15 3.74944856e-42]\n",
      " [1.00000000e+00 4.74661122e-12 1.86908728e-37]\n",
      " [1.00000000e+00 4.51225111e-16 2.87593812e-43]\n",
      " [1.00000000e+00 1.06738450e-13 8.03741867e-40]\n",
      " [3.29238876e-14 9.99988282e-01 1.17183089e-05]\n",
      " [4.63158003e-14 9.99951444e-01 4.85562056e-05]\n",
      " [5.36799470e-17 9.98801272e-01 1.19872798e-03]\n",
      " [2.75343826e-17 9.99957758e-01 4.22416332e-05]\n",
      " [3.30963042e-17 9.98591169e-01 1.40883082e-03]\n",
      " [3.95716810e-18 9.99898069e-01 1.01931386e-04]\n",
      " [1.34917330e-15 9.98694732e-01 1.30526758e-03]\n",
      " [1.40132994e-11 9.99999999e-01 5.35896283e-10]\n",
      " [4.22952290e-16 9.99985409e-01 1.45913298e-05]\n",
      " [9.16323757e-15 9.99985184e-01 1.48162736e-05]\n",
      " [1.27189739e-15 9.99999960e-01 3.99775730e-08]\n",
      " [6.70377685e-14 9.99962558e-01 3.74420905e-05]\n",
      " [2.67881579e-16 9.99999900e-01 9.96404119e-08]\n",
      " [2.18525566e-18 9.99200765e-01 7.99235463e-04]\n",
      " [1.09275796e-09 9.99999985e-01 1.37866738e-08]\n",
      " [6.53354501e-13 9.99997171e-01 2.82918647e-06]\n",
      " [2.33909793e-17 9.98673858e-01 1.32614176e-03]\n",
      " [1.41373651e-14 9.99999985e-01 1.48310542e-08]\n",
      " [7.37377553e-21 9.40359016e-01 5.96409837e-02]\n",
      " [1.17101749e-14 9.99999913e-01 8.72315142e-08]\n",
      " [1.36844152e-18 5.95317478e-01 4.04682522e-01]\n",
      " [1.26796296e-12 9.99999659e-01 3.40749389e-07]\n",
      " [2.14001583e-22 7.75052259e-01 2.24947741e-01]\n",
      " [8.67286954e-19 9.99959722e-01 4.02783229e-05]\n",
      " [6.38957815e-14 9.99998589e-01 1.41137315e-06]\n",
      " [8.58234333e-14 9.99992938e-01 7.06173230e-06]\n",
      " [4.03019853e-18 9.99287205e-01 7.12794526e-04]\n",
      " [2.14742603e-19 7.23982703e-01 2.76017297e-01]\n",
      " [5.82371525e-17 9.99034689e-01 9.65310832e-04]\n",
      " [4.45867980e-10 9.99999999e-01 1.29193634e-10]\n",
      " [1.21269628e-14 9.99999915e-01 8.47997404e-08]\n",
      " [1.23783938e-13 9.99999995e-01 5.30646072e-09]\n",
      " [5.24159336e-13 9.99999913e-01 8.71424124e-08]\n",
      " [1.38882139e-24 1.32329330e-01 8.67670670e-01]\n",
      " [7.20554945e-18 9.97830521e-01 2.16947937e-03]\n",
      " [6.07455593e-14 9.99787124e-01 2.12876120e-04]\n",
      " [1.02955325e-15 9.99702022e-01 2.97977715e-04]\n",
      " [7.88716723e-19 9.99744589e-01 2.55411148e-04]\n",
      " [1.51673066e-13 9.99999211e-01 7.88725552e-07]\n",
      " [4.91990588e-16 9.99988898e-01 1.11015512e-05]\n",
      " [6.97013830e-19 9.99960258e-01 3.97418763e-05]\n",
      " [7.28691891e-17 9.99840325e-01 1.59675010e-04]\n",
      " [1.57289373e-14 9.99999564e-01 4.36460667e-07]\n",
      " [5.97054037e-12 9.99999999e-01 8.16958114e-10]\n",
      " [2.54724408e-16 9.99984968e-01 1.50316264e-05]\n",
      " [4.48609492e-14 9.99999746e-01 2.54291073e-07]\n",
      " [8.19692342e-15 9.99996913e-01 3.08726823e-06]\n",
      " [1.96995993e-14 9.99997689e-01 2.31086157e-06]\n",
      " [7.27102829e-08 9.99999927e-01 6.16922977e-11]\n",
      " [1.52878729e-14 9.99997655e-01 2.34546826e-06]\n",
      " [7.53027584e-38 2.59003214e-10 1.00000000e+00]\n",
      " [5.75774051e-28 3.86209873e-04 9.99613790e-01]\n",
      " [9.11941120e-33 9.66153145e-07 9.99999034e-01]\n",
      " [6.03314564e-30 2.81175782e-04 9.99718824e-01]\n",
      " [1.52948495e-34 9.08071716e-08 9.99999909e-01]\n",
      " [4.25610923e-40 4.50468812e-09 9.99999995e-01]\n",
      " [1.83932301e-23 1.09173764e-01 8.90826236e-01]\n",
      " [1.83052943e-35 4.49829157e-06 9.99995502e-01]\n",
      " [8.98584267e-35 7.89877274e-06 9.99992101e-01]\n",
      " [3.82269202e-33 6.88536080e-09 9.99999993e-01]\n",
      " [9.31178167e-22 9.75138328e-03 9.90248617e-01]\n",
      " [2.10488465e-28 2.57167470e-04 9.99742833e-01]\n",
      " [1.25106288e-28 2.00429020e-05 9.99979957e-01]\n",
      " [9.23447809e-30 3.27349232e-05 9.99967265e-01]\n",
      " [1.39775525e-31 8.07012731e-08 9.99999919e-01]\n",
      " [1.90312703e-27 4.84189357e-06 9.99995158e-01]\n",
      " [5.33693305e-27 2.30116448e-03 9.97698836e-01]\n",
      " [1.28480822e-34 7.56177191e-08 9.99999924e-01]\n",
      " [3.93953856e-49 6.07127956e-13 1.00000000e+00]\n",
      " [6.30595666e-27 7.94361716e-02 9.20563828e-01]\n",
      " [7.36708980e-31 3.82143723e-07 9.99999618e-01]\n",
      " [4.54526701e-26 4.87342014e-04 9.99512658e-01]\n",
      " [5.74287106e-42 3.67188606e-09 9.99999996e-01]\n",
      " [1.17233509e-22 5.15756840e-02 9.48424316e-01]\n",
      " [7.42752314e-29 1.76356083e-05 9.99982364e-01]\n",
      " [3.69191658e-29 4.41508014e-04 9.99558492e-01]\n",
      " [7.38150390e-21 1.75501768e-01 8.24498232e-01]\n",
      " [1.04678627e-20 1.97771525e-01 8.02228475e-01]\n",
      " [3.22325780e-33 7.65249524e-07 9.99999235e-01]\n",
      " [1.40385308e-26 2.87906763e-02 9.71209324e-01]\n",
      " [2.60141947e-34 3.12558105e-06 9.99996874e-01]\n",
      " [3.67463179e-28 8.11765206e-05 9.99918823e-01]\n",
      " [3.99994239e-34 1.22954421e-07 9.99999877e-01]\n",
      " [2.66760940e-22 7.95049198e-01 2.04950802e-01]\n",
      " [8.26042748e-30 3.35601096e-02 9.66439890e-01]\n",
      " [5.13338919e-35 1.66059829e-08 9.99999983e-01]\n",
      " [8.40064416e-31 1.36669371e-07 9.99999863e-01]\n",
      " [1.90727683e-26 3.50382879e-03 9.96496171e-01]\n",
      " [7.66825762e-20 3.30963281e-01 6.69036719e-01]\n",
      " [4.81154966e-26 1.28438565e-04 9.99871561e-01]\n",
      " [4.22618631e-32 4.93605887e-08 9.99999951e-01]\n",
      " [6.14630216e-24 5.61305980e-05 9.99943869e-01]\n",
      " [5.75774051e-28 3.86209873e-04 9.99613790e-01]\n",
      " [7.80193284e-34 4.53001699e-08 9.99999955e-01]\n",
      " [1.76151086e-32 1.17533401e-08 9.99999988e-01]\n",
      " [6.93440115e-27 6.84499158e-06 9.99993155e-01]\n",
      " [1.11357779e-26 8.93498725e-04 9.99106501e-01]\n",
      " [6.82578037e-25 1.00689343e-03 9.98993107e-01]\n",
      " [1.20364762e-27 4.38251210e-06 9.99995617e-01]\n",
      " [5.86253475e-24 2.23287923e-02 9.77671208e-01]]\n"
     ]
    }
   ],
   "source": [
    "prob = mlogit_sm.predict(X)\n",
    "print(prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2]\n"
     ]
    }
   ],
   "source": [
    "yhat = np.argmax(prob,1)\n",
    "print(yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 0.18720288836716564\n",
      "            Iterations: 106\n",
      "            Function evaluations: 108\n",
      "            Gradient evaluations: 106\n"
     ]
    }
   ],
   "source": [
    "# LASSO with statmodels\n",
    "from statsmodels.discrete.discrete_model import MNLogit\n",
    "mlogit_sm = MNLogit(Y,X)\n",
    "mlogit_smL = mlogit_sm.fit_regularized(method=\"l1\", alpha=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2]\n"
     ]
    }
   ],
   "source": [
    "yhatL = np.argmax(mlogit_smL.predict(X),1)\n",
    "print(yhatL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[50  0  0]\n",
      " [ 0 48  2]\n",
      " [ 0  1 49]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "print(metrics.confusion_matrix(Y, yhatL))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[9.21716697e-01 7.82833027e-02 2.33566088e-27]\n",
      " [7.79476133e-01 2.20523867e-01 8.93341342e-26]\n",
      " [8.53254961e-01 1.46745039e-01 1.66609986e-26]\n",
      " [7.88652370e-01 2.11347630e-01 2.48705437e-25]\n",
      " [9.37128029e-01 6.28719709e-02 1.56501668e-27]\n",
      " [9.77119981e-01 2.28800190e-02 5.18264806e-26]\n",
      " [9.13153302e-01 8.68466983e-02 9.46660754e-26]\n",
      " [8.88526092e-01 1.11473908e-01 1.42641987e-26]\n",
      " [7.29395024e-01 2.70604976e-01 5.57294771e-25]\n",
      " [7.63419245e-01 2.36580755e-01 1.87160091e-26]\n",
      " [9.49465085e-01 5.05349149e-02 7.75964639e-28]\n",
      " [8.72133101e-01 1.27866899e-01 5.84566913e-26]\n",
      " [7.41836161e-01 2.58163839e-01 1.77301837e-26]\n",
      " [7.75680406e-01 2.24319594e-01 3.84185981e-27]\n",
      " [9.85572138e-01 1.44278617e-02 2.47528875e-30]\n",
      " [9.95802567e-01 4.19743304e-03 1.40422604e-28]\n",
      " [9.86211040e-01 1.37889599e-02 1.23867327e-27]\n",
      " [9.38361336e-01 6.16386637e-02 1.45923319e-26]\n",
      " [9.63907729e-01 3.60922713e-02 7.71829918e-27]\n",
      " [9.67595037e-01 3.24049628e-02 5.23810411e-27]\n",
      " [8.73615340e-01 1.26384660e-01 3.39760284e-26]\n",
      " [9.67538519e-01 3.24614808e-02 6.24190537e-26]\n",
      " [9.57115591e-01 4.28844086e-02 1.01532029e-28]\n",
      " [9.13463791e-01 8.65362086e-02 3.34211858e-23]\n",
      " [8.31221744e-01 1.68778256e-01 9.23033717e-25]\n",
      " [7.49839040e-01 2.50160960e-01 4.36388051e-25]\n",
      " [9.20971100e-01 7.90289001e-02 1.41943794e-24]\n",
      " [9.14401904e-01 8.55980958e-02 4.61551352e-27]\n",
      " [9.03362832e-01 9.66371679e-02 3.47349657e-27]\n",
      " [8.09405887e-01 1.90594113e-01 2.61825480e-25]\n",
      " [7.78545369e-01 2.21454631e-01 3.82143674e-25]\n",
      " [9.35061515e-01 6.49384850e-02 2.10749565e-25]\n",
      " [9.75765010e-01 2.42349904e-02 1.49668211e-29]\n",
      " [9.88390509e-01 1.16094913e-02 8.96651282e-30]\n",
      " [7.97564164e-01 2.02435836e-01 1.19994142e-25]\n",
      " [8.73557901e-01 1.26442099e-01 3.19232885e-27]\n",
      " [9.35693853e-01 6.43061467e-02 3.46742153e-28]\n",
      " [9.18554895e-01 8.14451049e-02 3.19901875e-28]\n",
      " [7.80567491e-01 2.19432509e-01 1.20473017e-25]\n",
      " [8.90633239e-01 1.09366761e-01 1.11722880e-26]\n",
      " [9.43905812e-01 5.60941879e-02 7.36907105e-27]\n",
      " [5.98064498e-01 4.01935502e-01 4.61114011e-23]\n",
      " [8.45523213e-01 1.54476787e-01 3.46058705e-26]\n",
      " [9.62346019e-01 3.76539807e-02 2.87648299e-23]\n",
      " [9.59235777e-01 4.07642231e-02 1.34577306e-24]\n",
      " [8.10072600e-01 1.89927400e-01 7.29151931e-25]\n",
      " [9.52764155e-01 4.72358446e-02 2.14253529e-27]\n",
      " [8.36598340e-01 1.63401660e-01 5.32940703e-26]\n",
      " [9.48341562e-01 5.16584382e-02 9.91885475e-28]\n",
      " [8.75155350e-01 1.24844650e-01 1.07024674e-26]\n",
      " [1.46556968e-06 9.99951661e-01 4.68737635e-05]\n",
      " [2.61612818e-06 9.99734378e-01 2.63005507e-04]\n",
      " [9.05837136e-08 9.96226230e-01 3.77367892e-03]\n",
      " [2.17063330e-07 9.99939767e-01 6.00160996e-05]\n",
      " [8.45022481e-08 9.96782603e-01 3.21731208e-03]\n",
      " [8.86846816e-08 9.99818452e-01 1.81459482e-04]\n",
      " [6.58031208e-07 9.91450447e-01 8.54889520e-03]\n",
      " [1.10050086e-04 9.99889949e-01 8.85909794e-10]\n",
      " [3.01861428e-07 9.99969329e-01 3.03692647e-05]\n",
      " [2.56036060e-06 9.99960453e-01 3.69869516e-05]\n",
      " [3.03181936e-06 9.99996917e-01 5.13925426e-08]\n",
      " [3.81763290e-06 9.99831834e-01 1.64348689e-04]\n",
      " [7.51934900e-07 9.99999122e-01 1.26170291e-07]\n",
      " [4.52500793e-08 9.98354008e-01 1.64594686e-03]\n",
      " [3.09743991e-04 9.99690197e-01 5.91871497e-08]\n",
      " [6.08448506e-06 9.99982046e-01 1.18690672e-05]\n",
      " [1.68674755e-07 9.95917084e-01 4.08274727e-03]\n",
      " [3.67551263e-06 9.99996301e-01 2.34852525e-08]\n",
      " [3.23629996e-09 9.29751068e-01 7.02489284e-02]\n",
      " [3.25170086e-06 9.99996614e-01 1.34582384e-07]\n",
      " [1.36135617e-08 2.72917490e-01 7.27082496e-01]\n",
      " [1.14101750e-05 9.99987685e-01 9.04502661e-07]\n",
      " [6.49292278e-10 7.68176487e-01 2.31823513e-01]\n",
      " [4.28331071e-08 9.99938292e-01 6.16649083e-05]\n",
      " [2.76704638e-06 9.99993637e-01 3.59639283e-06]\n",
      " [2.58164180e-06 9.99973643e-01 2.37757264e-05]\n",
      " [3.26034338e-08 9.98700238e-01 1.29972915e-03]\n",
      " [4.99605250e-09 5.27624519e-01 4.72375476e-01]\n",
      " [1.67894023e-07 9.97361013e-01 2.63881946e-03]\n",
      " [2.40800457e-04 9.99759199e-01 2.47905124e-10]\n",
      " [3.57829463e-06 9.99996296e-01 1.25923775e-07]\n",
      " [1.10346325e-05 9.99988958e-01 7.80559281e-09]\n",
      " [1.09425892e-05 9.99988875e-01 1.82052777e-07]\n",
      " [1.03220844e-10 4.27706246e-01 5.72293754e-01]\n",
      " [1.20716274e-07 9.93543713e-01 6.45616609e-03]\n",
      " [4.92058698e-06 9.97844585e-01 2.15049479e-03]\n",
      " [3.70153787e-07 9.98892464e-01 1.10716557e-03]\n",
      " [3.00307799e-08 9.99670108e-01 3.29861548e-04]\n",
      " [7.96749036e-06 9.99989502e-01 2.53092709e-06]\n",
      " [6.77789203e-07 9.99980727e-01 1.85949129e-05]\n",
      " [6.20213624e-08 9.99943078e-01 5.68604011e-05]\n",
      " [2.01177997e-07 9.99584387e-01 4.15411816e-04]\n",
      " [2.60524779e-06 9.99996631e-01 7.64040034e-07]\n",
      " [7.35610268e-05 9.99926438e-01 1.26411372e-09]\n",
      " [5.00171218e-07 9.99971273e-01 2.82265342e-05]\n",
      " [4.92150367e-06 9.99994427e-01 6.51489863e-07]\n",
      " [2.05979270e-06 9.99990184e-01 7.75572861e-06]\n",
      " [1.99377586e-06 9.99992275e-01 5.73092090e-06]\n",
      " [2.49370503e-03 9.97506295e-01 1.49821323e-10]\n",
      " [2.53406593e-06 9.99992011e-01 5.45534671e-06]\n",
      " [1.30523401e-13 7.29927818e-02 9.27007218e-01]\n",
      " [2.55527030e-11 3.13474228e-01 6.86525772e-01]\n",
      " [8.14203400e-13 2.32053844e-01 7.67946156e-01]\n",
      " [4.12974086e-12 3.41941139e-01 6.58058861e-01]\n",
      " [5.14008405e-13 1.99943075e-01 8.00056925e-01]\n",
      " [6.48156227e-15 3.28836741e-01 6.71163259e-01]\n",
      " [5.52634226e-10 3.98886622e-01 6.01113377e-01]\n",
      " [7.20832110e-14 4.04642133e-01 5.95357867e-01]\n",
      " [1.87946094e-13 4.43187119e-01 5.56812881e-01]\n",
      " [1.05657703e-12 3.16522158e-02 9.68347784e-01]\n",
      " [7.69261062e-10 1.05633069e-01 8.94366931e-01]\n",
      " [1.30016965e-11 3.26767892e-01 6.73232107e-01]\n",
      " [1.25073607e-11 1.77677362e-01 8.22322638e-01]\n",
      " [1.19153827e-11 3.33330990e-01 6.66669010e-01]\n",
      " [8.06648941e-12 1.20245249e-01 8.79754751e-01]\n",
      " [4.63234565e-11 6.64810134e-02 9.33518987e-01]\n",
      " [2.14978553e-11 2.89078591e-01 7.10921409e-01]\n",
      " [1.66782836e-13 7.37133132e-02 9.26286687e-01]\n",
      " [4.17231462e-17 4.14981466e-01 5.85018534e-01]\n",
      " [2.34450645e-11 4.93421897e-01 5.06578103e-01]\n",
      " [4.23502502e-12 9.33031254e-02 9.06696875e-01]\n",
      " [1.14426445e-10 2.18676058e-01 7.81323942e-01]\n",
      " [1.64421141e-15 4.15782518e-01 5.84217482e-01]\n",
      " [3.96441150e-10 3.12162046e-01 6.87837954e-01]\n",
      " [1.06019637e-11 1.20489794e-01 8.79510206e-01]\n",
      " [3.39088312e-12 2.79587965e-01 7.20412035e-01]\n",
      " [1.44004495e-09 2.91606726e-01 7.08393273e-01]\n",
      " [1.67306584e-09 2.41496516e-01 7.58503482e-01]\n",
      " [1.04023712e-12 2.74039223e-01 7.25960777e-01]\n",
      " [1.13558093e-11 3.81294930e-01 6.18705070e-01]\n",
      " [1.73198825e-13 3.80675074e-01 6.19324926e-01]\n",
      " [4.92179318e-12 8.10792626e-02 9.18920737e-01]\n",
      " [7.46490410e-13 2.39400546e-01 7.60599454e-01]\n",
      " [6.99405598e-10 7.53065833e-01 2.46934167e-01]\n",
      " [2.60540617e-12 4.79192777e-01 5.20807223e-01]\n",
      " [2.11899942e-13 1.79047173e-01 8.20952827e-01]\n",
      " [7.21793029e-12 4.58283649e-02 9.54171635e-01]\n",
      " [3.16193770e-11 2.57701455e-01 7.42298545e-01]\n",
      " [3.66254696e-09 2.60185098e-01 7.39814898e-01]\n",
      " [5.46691935e-11 1.31457317e-01 8.68542683e-01]\n",
      " [2.88094029e-12 8.73493418e-02 9.12650658e-01]\n",
      " [2.86627855e-10 6.06362277e-02 9.39363772e-01]\n",
      " [2.55527030e-11 3.13474228e-01 6.86525772e-01]\n",
      " [7.48042470e-13 1.17069244e-01 8.82930756e-01]\n",
      " [2.52745553e-12 4.73154156e-02 9.52684584e-01]\n",
      " [5.77642304e-11 8.96885319e-02 9.10311468e-01]\n",
      " [4.19423968e-11 3.47741084e-01 6.52258916e-01]\n",
      " [1.21080753e-10 1.72964392e-01 8.27035608e-01]\n",
      " [4.29502326e-11 4.75044467e-02 9.52495553e-01]\n",
      " [2.12843537e-10 2.45857208e-01 7.54142792e-01]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\no1papa\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\no1papa\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# sklearn\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "mlogitR = LogisticRegression(C=1e5)  # multi_class={'ovr','multinomial'}  \n",
    "X = iris.data[:, :4]\n",
    "mlogitR.fit(X,Y)\n",
    "muR = mlogitR.predict_proba(X)\n",
    "print(muR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2]\n"
     ]
    }
   ],
   "source": [
    "yhatR = np.argmax(muR,1)\n",
    "print(yhatR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[50  0  0]\n",
      " [ 0 48  2]\n",
      " [ 0  1 49]]\n"
     ]
    }
   ],
   "source": [
    "print(metrics.confusion_matrix(Y, yhatR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
